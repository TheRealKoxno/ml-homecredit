ML22
==============================

1) 
Testing cookiecutter

Project Organization
------------

    ├── Makefile           <- Makefile with commands like `make data` or `make train`
    ├── README.md          <- The top-level README for developers using this project.
    ├── data
    │   └── raw            <- The original, immutable data dump.
    │
    ├── models             <- Trained and serialized models, model predictions, or model summaries
    │
    ├── notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
    │                         the creator's initials, and a short `-` delimited description, e.g.
    │                         `1.0-jqp-initial-data-exploration`.
    │
    ├── requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
    │                         generated with `pip freeze > requirements.txt`
    │
    └── src            <- Source code for use in this project.

2)
Создаю разные модели для Соревнования Home Credit Default Risk.

# 1 МОДЕЛЬ
Отбираю первые попавшиеся данные.
Обрабатываю данные (заменяю NaN's на Медианные значения, нормализую выбросы, делаю бинарные классы, сокращаю количество категорий в категориальных признаках).

PRIV - 0.50000 , PUBL - 0.50000

# 2 МОДЕЛЬ
Из обработанных для 1 модели данных извлекаю объекты с ответами = 1 и столько же объектов, ответ которых = 0, тем самым избавляюсь от перекоса в обучающей выборке. 

PRIV - 0.59199 , PUBL - 0.58009

# 3 МОДЕЛЬ
Выбираю бинарные и категориальные признаки. Проверяю зависимости между объектами с ответами 1 и (0 & 1). Категории в группах, где соотношение больше остальных отличается, откладываю для создания отдельных бинарных колонок с признаками. Применяю к таким колонкам One Hot Encode, написав собственную функцию. 

PRIV - 0.59737 , PUBL - 0.59423

# 3A МОДЕЛЬ
Нормализую признаки в колонке REGION_RATING_CLIENT через minmax scaller. Результат ухудшается.

PRIV - 0.59736 , PUBL - 0.59418

# 4 МОДЕЛЬ
Обучаю модель на числовых признаках. Большинство колонок оставляю as is, NaN's заменяю на Медианы, колонки с большими выбросами ограничиваю по макс мин значениям.

PRIV - 0.53320 , PUBL - 0.53613

# 4A МОДЕЛЬ
Вместо замены NaN's на медиану в 4А отбрасываю строчки с NaN's в TOTALAREA_MODE. NaN's в OWN_CAR_AGE заполняю новой Медианой. Результат ухудшился, скорее всего из-за сильного сокращения данных для обучения.

PRIV - 0.49777 , PUBL - 0.50513

# 4B МОДЕЛЬ
Привожу данные из 4A модели к 1 масштабу через minmax.

PRIV - 0.53086 , PUBL - 0.54154

# 4C МОДЕЛЬ
Привожу данные из 4 модели к 1 масштабу через minmax.

PRIV - 0.55694 , PUBL - 0.56480

# 4D МОДЕЛЬ
Вместо Медиан подставляю макс значения в OWN_CAR_AGE.

PRIV - 0.51277 , PUBL - 0.52710

# 4E МОДЕЛЬ
Дропаю колонку OWN_CAR_AGE

PRIV - 0.53320 , PUBL - 0.53613

# 5 МОДЕЛЬ
Превращаю некоторые числовые признаки в категориальные. Привожу признаки к 1 масштабу. Из интересных предположений:

OWN_CAR_AGE - Делю на категориальные признаки.
1) Владение машиной с 0 до 5 лет вклюительно = 1 (вы вообще видели цены на новые тачки в 2021??).

2) Остальные владельцы авто в отдельную колонку.

DAYS_LAST_PHONE_CHANGE - Допускаю, что есть 3 категории людей. Делю на 2 категории (1 и 3 номера).

1) Владение телефоном > 6.5 лет. Телефон людям не интересен. Купили его, чтобы звонить. Отдельная группа, в которой не хочу искать зависимости.

2) Владение телефоном от 3 до 7 лет - не обновляют, потому что есть покупки важнее.

3) Владение телефоном до 3 - следят за новыми моделями, покупают, потому что могут.

PRIV - 0.46938 , PUBL - 0.47176

# 5A МОДЕЛЬ
Нормализую получившиеся в 5 модели признаки

PRIV - 0.57018 , PUBL - 0.56914

# 5B МОДЕЛЬ
Пробую изменить диапазон own car от 0 до 3 (вместо 0-5).

PRIV - 0.56921 , PUBL - 0.57394

# 5C МОДЕЛЬ
Попробовать дропнуть own car больше 5

PRIV - 0.56836 , PUBL - 0.57438

# 5D МОДЕЛЬ
Попробовать дропнуть 6.5<

PRIV - 0.56797 , PUBL - 0.57387

# 6 МОДЕЛЬ
Совмещаю числовые признаки с категориальными

PRIV - 0.61222 , PUBL - 0.60474 (BEST RESULT)


3)
Выводы по результатам.

*1 вывод:

Логистическая регрессия не справляется с перекосом ответов в выборке. 
Если объектов с одним ответом больше, чем с другим - особенности мЕньшей части затеряются на фоне бОльшей.

*2 вывод:

Приведение признаков к 1 масштабу приводит к лучшим результатам.

*3 вывод:

Нормализованные числовые признаки будто больше влияют на результат, 
нежели чем бинарные признаки, выделенные из категориальных.

*4 вывод:

Объединение обработанных признаков для обучения модели дает лучший результат, 
нежели чем категориальные и числовые признаки по отдельности.

*5 вывод:

Не обязательно сохранять соотношение "чем больше значение признака, тем выше вероятность выпадения положительного ответа". 
Соотношение может меняться в отрицательную сторону (ниже значение -> меньше вероятность) ((по другому признаку)). 
Обратная пропорция вносит не меньший вклад (меньше значение -> больше вероятность).




